{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6aff5f",
   "metadata": {},
   "source": [
    "### Function Gemma - POC\n",
    "\n",
    "Google example: https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/functiongemma/finetuning-with-functiongemma.ipynb#scrollTo=2d4f0a33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1bccccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -q transformers==4.57.3 datasets accelerate evaluate trl==0.26.2 protobuf sentencepiece\n",
    "! pip install -q huggingface_hub tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f2817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3375b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import get_json_schema\n",
    "\n",
    "# TOOLS internas\n",
    "\n",
    "def pagamento_pix(\n",
    "    valor: float,\n",
    "    nome_estabelecimento: str\n",
    ") -> str:\n",
    "    \"\"\"Realiza um pagamento via Pix na maquininha.\n",
    "\n",
    "    Args:\n",
    "        valor: Valor do pagamento em reais (BRL)\n",
    "        nome_estabelecimento: Nome exibido na maquininha\n",
    "    \"\"\"\n",
    "    return \"Pagamento Pix realizado\"\n",
    "\n",
    "\n",
    "def imprimir_comprovante(\n",
    "    tipo: str\n",
    ") -> str:\n",
    "    \"\"\"Imprime o comprovante do pagamento.\n",
    "\n",
    "    Args:\n",
    "        tipo: Tipo do comprovante (\"cliente\" ou \"estabelecimento\")\n",
    "    \"\"\"\n",
    "    return \"Comprovante impresso\"\n",
    "\n",
    "\n",
    "# Macro tool\n",
    "\n",
    "def pagamento(\n",
    "    valor: float,\n",
    "    nome_estabelecimento: str,\n",
    "    imprimir: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Macro tool de pagamento.\n",
    "    Realiza pagamento via Pix e imprime comprovante.\n",
    "\n",
    "    Args:\n",
    "        valor: Valor do pagamento em reais (BRL)\n",
    "        nome_estabelecimento: Nome exibido na maquininha\n",
    "        imprimir: Se deve imprimir comprovante\n",
    "    \"\"\"\n",
    "\n",
    "    resultado_pagamento = pagamento_pix(\n",
    "        valor=valor,\n",
    "        nome_estabelecimento=nome_estabelecimento\n",
    "    )\n",
    "\n",
    "    if imprimir:\n",
    "        imprimir_comprovante(tipo=\"cliente\")\n",
    "\n",
    "    return resultado_pagamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/functiongemma-270m-it\", device_map=\"auto\", token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/functiongemma-270m-it\", dtype=\"auto\", device_map=\"auto\", token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820c3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "# FunctionGemma special tokens \n",
    "START_TURN = \"\"\n",
    "END_TURN = \"\"\n",
    "START_DECL = \"\"\n",
    "END_DECL = \"\"\n",
    "START_CALL = \"\"\n",
    "END_CALL = \"\"\n",
    "ESCAPE = \"\"\n",
    "\n",
    "FUNCTION_DECLARATIONS = f\"\"\"{START_DECL}declaration:pagamento{{description:{ESCAPE}Realiza um pagamento via Pix na maquininha e opcionalmente imprime o comprovante{ESCAPE},parameters:{{properties:{{valor:{{description:{ESCAPE}Valor do pagamento em reais (BRL){ESCAPE},type:{ESCAPE}NUMBER{ESCAPE}}},nome_estabelecimento:{{description:{ESCAPE}Nome exibido na maquininha{ESCAPE},type:{ESCAPE}STRING{ESCAPE}}},imprimir:{{description:{ESCAPE}Indica se deve imprimir o comprovante{ESCAPE},type:{ESCAPE}BOOLEAN{ESCAPE}}}}},required:[{ESCAPE}valor{ESCAPE},{ESCAPE}nome_estabelecimento{ESCAPE}],type:{ESCAPE}OBJECT{ESCAPE}}}}}{END_DECL}\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"{START_TURN}developer\n",
    "Você é um modelo especialista em **chamada de funções (function calling)** para uma **maquininha de pagamento (POS)**.\n",
    "\n",
    "Seu papel é:\n",
    "- Interpretar a solicitação do usuário\n",
    "- Identificar a função correta a ser chamada\n",
    "- Retornar **exclusivamente** uma chamada de função válida, no formato especificado\n",
    "\n",
    "As funções disponíveis estão descritas abaixo:\n",
    "{FUNCTION_DECLARATIONS}\n",
    "\n",
    "Regras importantes:\n",
    "- Chame **apenas** funções listadas acima\n",
    "- Preencha corretamente todos os parâmetros obrigatórios\n",
    "- Use somente os tipos definidos no schema\n",
    "- Não gere texto explicativo fora da chamada de função\n",
    "- Se a solicitação **não corresponder** a nenhuma função disponível, retorne exatamente:\n",
    "  \"Não especializado para esse tipo de ação\"\n",
    "\n",
    "{END_TURN}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee613438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(sample):\n",
    "    \"\"\"\n",
    "    Input sample:\n",
    "    {\n",
    "      \"user_content\": \"pix de 50 reais sem comprovante\",\n",
    "      \"tool_name\": \"pagamento\",\n",
    "      \"tool_arguments\": \"{\\\"valor\\\":50,\\\"nome_estabelecimento\\\":\\\"Padaria Central\\\",\\\"imprimir\\\":false}\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = sample[\"user_content\"]\n",
    "    tool_name = sample[\"tool_name\"]\n",
    "    tool_args = json.loads(sample[\"tool_arguments\"])\n",
    "\n",
    "    # Prompt (entrada)\n",
    "    prompt = f\"\"\"{SYSTEM_PROMPT}{START_TURN}user\n",
    "{user_content}\n",
    "{END_TURN}\n",
    "{START_TURN}model\n",
    "\"\"\"\n",
    "\n",
    "    # Completion (chamada da função)\n",
    "    params_str = \",\".join(\n",
    "        [f\"{k}:{ESCAPE}{v}{ESCAPE}\" for k, v in tool_args.items()]\n",
    "    )\n",
    "\n",
    "    completion = f\"{START_CALL}call:{tool_name}{{{params_str}}}{END_CALL}\"\n",
    "\n",
    "    return {\"text\": prompt + completion}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc27442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 114 raw examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 114/114 [00:00<00:00, 10856.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset prepared:\n",
      "   Train: 57 examples\n",
      "   Test:  57 examples\n",
      "\n",
      "============================================================\n",
      "Sample training example:\n",
      "============================================================\n",
      "developer\n",
      "Você é um modelo especialista em **chamada de funções (function calling)** para uma **maquininha de pagamento (POS)**.\n",
      "\n",
      "Seu papel é:\n",
      "- Interpretar a solicitação do usuário\n",
      "- Identificar a função correta a ser chamada\n",
      "- Retornar **exclusivamente** uma chamada de função válida, no formato especificado\n",
      "\n",
      "As funções disponíveis estão descritas abaixo:\n",
      "declaration:pagamento{description:Realiza um pagamento via Pix na maquininha e opcionalmente imprime o comprovante,parameters:{properties:{valor:{description:Valor do pagamento em reais (BRL),type:NUMBER},nome_estabelecimento:{description:Nome exibido na maquininha,type:STRING},imprimir:{description:Indica se deve imprimir o comprovante,type:BOOLEAN}},required:[valor,nome_estabelecimento],type:OBJECT}}\n",
      "\n",
      "Regras importantes:\n",
      "- Chame **apen\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load and convert dataset\n",
    "# =============================================================================\n",
    "raw_data = []\n",
    "with open('machine_actions.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        raw_data.append(json.loads(line.strip()))\n",
    "\n",
    "print(f\"Loaded {len(raw_data)} raw examples\")\n",
    "\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "dataset = dataset.map(create_training_example, remove_columns=dataset.features)\n",
    "\n",
    "# Split into train/test (90%/10%)\n",
    "dataset = dataset.train_test_split(test_size=0.5, shuffle=True, seed=42)\n",
    "\n",
    "print(f\"\\nDataset prepared:\")\n",
    "print(f\"   Train: {len(dataset['train'])} examples\")\n",
    "print(f\"   Test:  {len(dataset['test'])} examples\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Sample training example:\")\n",
    "print(\"=\"*60)\n",
    "print(dataset['train'][0]['text'][:800])\n",
    "print(\"...\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aabc681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/functiongemma-270m-it...\n",
      "   (Downloads ~540MB on first run, then uses cache)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded!\n",
      "   Parameters: 268,098,176\n",
      "   Memory: ~0.5 GB (bfloat16)\n",
      "   Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# =============================================================================\n",
    "# Load FunctionGemma base model\n",
    "# =============================================================================\n",
    "BASE_MODEL = \"google/functiongemma-270m-it\"\n",
    "\n",
    "print(f\"Loading {BASE_MODEL}...\")\n",
    "print(\"   (Downloads ~540MB on first run, then uses cache)\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.bfloat16,      # 16-bit to save VRAM\n",
    "    device_map=\"auto\",                # Automatically load to GPU\n",
    "    attn_implementation=\"eager\"       # Without FlashAttention for compatibility\n",
    ")\n",
    "\n",
    "# Tokenizer converts text to tokens and back\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "print(f\"\\nModel loaded!\")\n",
    "print(f\"   Parameters: {model.num_parameters():,}\")\n",
    "print(f\"   Memory: ~{model.num_parameters() * 2 / 1e9:.1f} GB (bfloat16)\")\n",
    "print(f\"   Device: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4867535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "checkpoint_dir = f\"/content-function-gemma\"\n",
    "learning_rate = 5e-5 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf6e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "import torch\n",
    "\n",
    "torch_dtype = model.dtype\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=checkpoint_dir,              # directory to save and repository id\n",
    "    max_length=512,                         # max sequence length for model and packing of the dataset\n",
    "    packing=False,                          # Groups multiple samples in the dataset into a single sequence\n",
    "    num_train_epochs=3,                     # number of training epochs\n",
    "    per_device_train_batch_size=4,          # batch size per device during training\n",
    "    gradient_checkpointing=False,           # Caching is incompatible with gradient checkpointing\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    logging_steps=1,                        # log every step\n",
    "    #save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
    "    eval_strategy=\"epoch\",                  # evaluate checkpoint every epoch\n",
    "    learning_rate=learning_rate,            # learning rate\n",
    "    fp16=True if torch_dtype == torch.float16 else False,   # use float16 precision\n",
    "    bf16=True if torch_dtype == torch.bfloat16 else False,  # use bfloat16 precision\n",
    "    lr_scheduler_type=\"constant\",            # use constant learning rate scheduler\n",
    "    push_to_hub=True,                        # push model to hub\n",
    "    report_to=\"tensorboard\",                 # report metrics to tensorboard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07fb03d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding EOS to train dataset: 100%|██████████| 57/57 [00:00<00:00, 9348.74 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 57/57 [00:00<00:00, 980.56 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 57/57 [00:00<00:00, 6887.40 examples/s]\n",
      "Adding EOS to eval dataset: 100%|██████████| 57/57 [00:00<00:00, 8848.74 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 57/57 [00:00<00:00, 1278.18 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 57/57 [00:00<?, ? examples/s]\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "# Create Trainer object\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f6b92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 0}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 04:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.102062</td>\n",
       "      <td>0.141911</td>\n",
       "      <td>17376.000000</td>\n",
       "      <td>0.977363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.094530</td>\n",
       "      <td>0.080961</td>\n",
       "      <td>34752.000000</td>\n",
       "      <td>0.976176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.081038</td>\n",
       "      <td>0.055808</td>\n",
       "      <td>52128.000000</td>\n",
       "      <td>0.978748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (5 / 5): 100%|██████████|  574MB /  574MB,  261MB/s  \n",
      "New Data Upload: 100%|██████████| 9.78kB / 9.78kB, 5.43kB/s  \n"
     ]
    }
   ],
   "source": [
    "# Start training, the model will be automatically saved to the Hub and the output directory\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model again to the Hugging Face Hub\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf51ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (5 / 5): 100%|██████████|  574MB /  574MB,  274MB/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved locally to model-tuned-final/\n"
     ]
    }
   ],
   "source": [
    "FINAL_MODEL_DIR = f\"model-tuned-final\"\n",
    "\n",
    "# Save model weights and config\n",
    "trainer.save_model(FINAL_MODEL_DIR)\n",
    "\n",
    "# Save tokenizer (needed for inference)\n",
    "tokenizer.save_pretrained(FINAL_MODEL_DIR)\n",
    "\n",
    "print(f\"Model saved locally to {FINAL_MODEL_DIR}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99946def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando modelo fine-tuned\n",
      "============================================================\n",
      "\n",
      "Usuário: quero pagar 50 reais no pix\n",
      "Modelo: call:pagamento{valor:50,nome_estabelecimento:Mercado Verde,imprimir:True}<eos>\n",
      "------------------------------------------------------------\n",
      "\n",
      "Usuário: faz um pix de 30 reais\n",
      "Modelo: call:pagamento{valor:30,nome_estabelecimento:Mercado Verde,imprimir:True}<eos>\n",
      "------------------------------------------------------------\n",
      "\n",
      "Usuário: pix de 100 reais sem comprovante\n",
      "Modelo: call:pagamento{valor:100,nome_estabelecimento:Hotel Central,imprimir:False}<eos>\n",
      "------------------------------------------------------------\n",
      "\n",
      "Usuário: pagar 25 reais via pix\n",
      "Modelo: call:pagamento{valor:25,nome_estabelecimento:Hotel Central,imprimir:True}<eos>\n",
      "------------------------------------------------------------\n",
      "\n",
      "Usuário: realiza um pagamento pix de 80 reais sem imprimir\n",
      "Modelo: call:pagamento{valor:80,nome_estabelecimento:Hotel Central,imprimir:False}<eos>\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Testar o modelo fine-tuned com novos prompts \n",
    "# =============================================================================\n",
    "# CRÍTICO: usar exatamente o mesmo formato Google FunctionGemma do treino\n",
    "\n",
    "test_prompts = [\n",
    "    \"quero pagar 50 reais no pix\",\n",
    "    \"faz um pix de 30 reais\",\n",
    "    \"pix de 100 reais sem comprovante\",\n",
    "    \"pagar 25 reais via pix\",\n",
    "    \"realiza um pagamento pix de 80 reais sem imprimir\",\n",
    "]\n",
    "\n",
    "print(\"Testando modelo fine-tuned\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    # Prompt no MESMO formato do treino\n",
    "    input_text = f\"\"\"{SYSTEM_PROMPT}{START_TURN}user\n",
    "{prompt}\n",
    "{END_TURN}\n",
    "{START_TURN}model\n",
    "\"\"\"\n",
    "    \n",
    "    # Tokenizar e enviar para GPU\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Gerar resposta\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=80,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decodificar apenas tokens novos\n",
    "    response = tokenizer.decode(\n",
    "        outputs[0][inputs[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nUsuário: {prompt}\")\n",
    "    print(f\"Modelo: {response.strip()}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746a380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "func-gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
